{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "baf26aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8100558659217877\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84       105\n",
      "           1       0.79      0.74      0.76        74\n",
      "\n",
      "    accuracy                           0.81       179\n",
      "   macro avg       0.81      0.80      0.80       179\n",
      "weighted avg       0.81      0.81      0.81       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the Titanic dataset (you can download it from Kaggle)\n",
    "# Make sure you adjust the path to the dataset file\n",
    "data = pd.read_csv(\"C:/titanic_dataset.csv\")\n",
    "\n",
    "# Data preprocessing\n",
    "# Drop unnecessary columns and handle missing values\n",
    "data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin', 'Embarked'], axis=1, inplace=True)\n",
    "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
    "data['Fare'].fillna(data['Fare'].median(), inplace=True)\n",
    "data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "# Create dummy variables for the 'Pclass' column\n",
    "data = pd.get_dummies(data, columns=['Pclass'], prefix='Pclass')\n",
    "\n",
    "# Split the dataset into features and target variable\n",
    "X = data.drop('Survived', axis=1)\n",
    "y = data['Survived']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba531b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 79.33%\n",
      "     PassengerId  Survived\n",
      "0            892         0\n",
      "1            893         0\n",
      "2            894         1\n",
      "3            895         1\n",
      "4            896         1\n",
      "..           ...       ...\n",
      "413         1305         1\n",
      "414         1306         1\n",
      "415         1307         0\n",
      "416         1308         1\n",
      "417         1309         1\n",
      "\n",
      "[418 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Titanic dataset (assuming you have 'train.csv' and 'test.csv' files)\n",
    "train_data = pd.read_csv(\"C:/titanictrain.csv\")\n",
    "test_data = pd.read_csv(\"C:/titanictest.csv\")\n",
    "\n",
    "features = ['Pclass', 'Age', 'Sex']\n",
    "train_data['Age'].fillna(train_data['Age'].median(), inplace=True)\n",
    "test_data['Age'].fillna(test_data['Age'].median(), inplace=True)\n",
    "\n",
    "train_data['Sex'] = train_data['Sex'].map({'female': 0, 'male': 1})\n",
    "test_data['Sex'] = test_data['Sex'].map({'female': 0, 'male': 1})\n",
    "\n",
    "# Define the target variable (Survived)\n",
    "target = train_data['Survived']\n",
    "\n",
    "# Select and preprocess the features\n",
    "X = train_data[features]\n",
    "X_test = test_data[features]\n",
    "\n",
    "# Split the dataset into a training and testing set\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build a Random Forest Classifier model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "valid_predictions = model.predict(X_valid)\n",
    "\n",
    "# Calculate accuracy on the validation set\n",
    "accuracy = accuracy_score(y_valid, valid_predictions)\n",
    "print(f'Validation Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "# Add the predictions to the test_data DataFrame\n",
    "test_data['Survived'] = test_predictions\n",
    "\n",
    "# Display the test_data DataFrame with survival predictions\n",
    "print(test_data[['PassengerId', 'Survived']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc1fba0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
